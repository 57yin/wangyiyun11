import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
import streamlit as st
from collections import Counter
import jieba
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from pathlib import Path
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re

# ä¾èµ–å®‰è£…ç›¸å…³å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰
def install_deps():
    required_packages = ['streamlit>=1.28.0', 'pandas', 'plotly', 'openpyxl', 'numpy', 'jieba', 'scikit-learn']
    try:
        import pkg_resources
        installed = {p.key for p in pkg_resources.working_set}
        print(f"æ­£åœ¨æ£€æŸ¥å¹¶å®‰è£…/å‡çº§ä¾èµ–åº“: {', '.join(required_packages)}")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "--upgrade", *required_packages])
        print("ä¾èµ–åº“å®‰è£…/å‡çº§å®Œæˆã€‚")
    except Exception as e:
        print(f"è‡ªåŠ¨å®‰è£…ä¾èµ–å¤±è´¥: {e}")
        print("è¯·æ‰‹åŠ¨å®‰è£…ä»¥ä¸‹åº“: " + ", ".join(required_packages))

# é¦–æ¬¡è¿è¡Œä¾èµ–æ£€æŸ¥ï¼ˆä¿æŒä¸å˜ï¼‰
try:
    from importlib.metadata import version
    st_version = version('streamlit')
    print(f"å½“å‰ Streamlit ç‰ˆæœ¬: {st_version}")
    if tuple(map(int, st_version.split('.'))) < (1, 28, 0):
        print("Streamlit ç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦å‡çº§...")
        raise ImportError("Streamlit version too old")
    # æ£€æŸ¥scikit-learnæ˜¯å¦å®‰è£…
    import sklearn
except (ImportError, Exception):
    print("æ£€æµ‹åˆ°ç¼ºå¤±ä¾èµ–æˆ–ç‰ˆæœ¬ä¸å…¼å®¹ï¼Œæ­£åœ¨å°è¯•è‡ªåŠ¨å®‰è£…...")
    install_deps()
    # é‡æ–°å¯¼å…¥æ‰€æœ‰åº“
    import pandas as pd
    import plotly.express as px
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    import numpy as np
    import streamlit as st
    from collections import Counter
    import jieba
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    import re

# ---------------------- å…¨å±€é…ç½® ----------------------
st.set_page_config(
    page_title="ç½‘æ˜“äº‘æ­Œå•+æ¦œå•è¯„è®ºç»¼åˆæ•°æ®åˆ†æå·¥å…·",
    page_icon="ğŸµ",
    layout="wide",
    initial_sidebar_state="expanded"  
)

# è‡ªå®šä¹‰æ ·å¼ï¼ˆä¿æŒä¸å˜ï¼Œæ³¨æ„åç»­è‹¥ä»æœ‰å¸ƒå±€å†²çªå¯ç®€åŒ–è°ƒè¯•ï¼‰
custom_style = """
    <style>
        /* å…¨å±€é‡ç½®ä¸åŸºç¡€æ ·å¼ */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        /* é¡µé¢èƒŒæ™¯æ¸å˜ */
        .main {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        /* éšè—é»˜è®¤èœå•å’Œé¡µè„š */
        #MainMenu {visibility: hidden !important;}
        footer {visibility: hidden !important;}
        header {visibility: hidden !important;}
        
        /* æ¨èå¡ç‰‡æ ·å¼ */
        .recommendation-card {
            background-color: #ffffff;
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 15px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            border-left: 5px solid #1DB954;
        }
        
        .recommendation-card h4 {
            color: #1DB954;
            margin-bottom: 10px;
        }
        
        .recommendation-card p {
            margin: 5px 0;
            color: #333333;
        }
        
        .recommendation-card .match-score {
            background-color: #1DB954;
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            display: inline-block;
            margin-top: 10px;
        }
        
        /* å…¶ä»–æ ·å¼ä¿æŒä¸å˜... */
    </style>
"""
st.markdown(custom_style, unsafe_allow_html=True)

# é¢œè‰²é…ç½®ï¼ˆä¿æŒä¸å˜ï¼‰
COLOR_PALETTE = {
    'primary': '#1DB954',      
    'primary_light': '#1ed760',
    'primary_dark': '#1a9e48', 
    'secondary': '#FF6B6B',    
    'accent': '#4ECDC4',       
    'background': '#F8F9FA',   
    'text': '#2d3436',         
    'light_text': '#6c757d',   
    'card_bg': '#FFFFFF',      
    'success': '#28a745',      
    'warning': '#ffc107',      
    'danger': '#dc3545',       
    'info': '#17a2b8'          
}

# æƒ…æ„Ÿåˆ†æé˜ˆå€¼ï¼ˆä¿æŒä¸å˜ï¼‰
NEGATIVE_THRESHOLD = 0.4  
POSITIVE_THRESHOLD = 0.6  

# æ•°æ®æºé…ç½®ï¼ˆä¿æŒä¸å˜ï¼‰
TYPE_LIST_STYLE = ['æµè¡Œ', 'çƒ­è¡€', '00å', 'åè¯­', 'ä¼¤æ„Ÿ', 'å¤œæ™š', 'æ²»æ„ˆ', 'æ”¾æ¾', 'æ„ŸåŠ¨', 'å®‰é™', 'æ°‘è°£', 'å­¤ç‹¬', 'æµªæ¼«']
TYPE_LIST_RANK = ['çƒ­æ­Œæ¦œ', 'æ–°æ­Œæ¦œ', 'é£™å‡æ¦œ', 'åŸåˆ›æ¦œ']
DATA_DIR = Path(__file__).parent  
RANK_DATA_ROOT = "multi_playlist_results"  

# ---------------------- æ•°æ®åŠ è½½ä¸é¢„å¤„ç†æ¨¡å—ï¼ˆä¿æŒä¸å˜ï¼‰ ----------------------
def load_style_playlist_data():
    all_data = []
    found_files = []
    skipped_files = []
    for cat in TYPE_LIST_STYLE:
        file_path = DATA_DIR / f"{cat}.csv"
        if file_path.exists():
            try:
                df = pd.read_csv(file_path, index_col=0, on_bad_lines='skip')
                if df.empty:
                    skipped_files.append(f"{cat}.csv (æ–‡ä»¶ä¸ºç©º)")
                    continue
                required_columns = ['åç§°', 'åˆ›å»ºæ—¥æœŸ', 'æ’­æ”¾æ¬¡æ•°', 'æ”¶è—é‡', 'è½¬å‘é‡', 'è¯„è®ºæ•°', 'æ­Œå•é•¿åº¦', 'tag1']
                if not all(col in df.columns for col in required_columns):
                    missing_cols = [col for col in required_columns if col not in df.columns]
                    skipped_files.append(f"{cat}.csv (ç¼ºå°‘åˆ—: {', '.join(missing_cols)})")
                    continue
                df['åˆ†ç±»'] = cat.strip()
                all_data.append(df)
                found_files.append(cat)
            except Exception as e:
                skipped_files.append(f"{cat}.csv (è¯»å–é”™è¯¯: {str(e)})")
        else:
            skipped_files.append(f"{cat}.csv (æ–‡ä»¶ä¸å­˜åœ¨)")
    if not all_data:
        return pd.DataFrame(), found_files, skipped_files, 0
    combined_df = pd.concat(all_data, ignore_index=True)
    duplicate_cols = ['åç§°', 'åˆ†ç±»', 'åˆ›å»ºæ—¥æœŸ']
    before_count = len(combined_df)
    combined_df = combined_df.drop_duplicates(subset=duplicate_cols, keep='first')
    after_count = len(combined_df)
    dup_count = before_count - after_count
    combined_df['åˆ›å»ºæ—¥æœŸ'] = pd.to_datetime(combined_df['åˆ›å»ºæ—¥æœŸ'], errors='coerce')
    numeric_cols = ['æ’­æ”¾æ¬¡æ•°', 'æ”¶è—é‡', 'è½¬å‘é‡', 'è¯„è®ºæ•°', 'æ­Œå•é•¿åº¦']
    for col in numeric_cols:
        combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce').fillna(0).astype(int)
    combined_df['tag1'] = combined_df['tag1'].str.replace('nan', '').str.strip()
    combined_df['æ”¶è—æ’­æ”¾æ¯”'] = (combined_df['æ”¶è—é‡'] / combined_df['æ’­æ”¾æ¬¡æ•°'] * 100).round(4)
    combined_df['è¯„è®ºæ’­æ”¾æ¯”'] = (combined_df['è¯„è®ºæ•°'] / combined_df['æ’­æ”¾æ¬¡æ•°'] * 100).round(4)
    combined_df['åˆ›å»ºæœˆä»½'] = combined_df['åˆ›å»ºæ—¥æœŸ'].dt.to_period('M')
    
    # ä¸ºæ¨èç³»ç»Ÿæ·»åŠ çš„é¢„å¤„ç†
    # 1. åˆ›å»ºæ­Œå•ç‰¹å¾æ–‡æœ¬ï¼ˆåç§°+åˆ†ç±»+æ ‡ç­¾ï¼‰
    combined_df['ç‰¹å¾æ–‡æœ¬'] = combined_df['åç§°'] + ' ' + combined_df['åˆ†ç±»'] + ' ' + combined_df['tag1']
    # 2. å¤„ç†ç¼ºå¤±å€¼
    combined_df['ç‰¹å¾æ–‡æœ¬'] = combined_df['ç‰¹å¾æ–‡æœ¬'].fillna('')
    
    return combined_df, found_files, skipped_files, dup_count

def load_rank_comment_data():
    all_rank_data = []
    found_ranks = []
    skipped_ranks = []
    for rank_name in TYPE_LIST_RANK:
        rank_dir = DATA_DIR / RANK_DATA_ROOT / rank_name
        dataset_path = rank_dir / f"{rank_name}_dataset.csv"
        comment_dir = rank_dir / "detailed_comments"  
        if dataset_path.exists():
            try:
                df = pd.read_csv(dataset_path, on_bad_lines='skip', encoding='utf-8-sig')
                if df.empty:
                    skipped_ranks.append(f"{rank_name} (æ–‡ä»¶ä¸ºç©º)")
                    continue
                required_columns = ['æ­Œæ›²ID', 'æ­Œæ›²åç§°', 'æ­Œæ‰‹', 'è¯„è®ºæ€»æ•°', 'ç§¯æè¯„è®ºæ•°', 'æ¶ˆæè¯„è®ºæ•°', 'ä¸­ç«‹è¯„è®ºæ•°', 'ç§¯æè¯„è®ºå æ¯”', 'æ¶ˆæè¯„è®ºå æ¯”', 'ä¸­ç«‹è¯„è®ºå æ¯”', 'é«˜é¢‘å­—çœ¼']
                missing_cols = [col for col in required_columns if col not in df.columns]
                if missing_cols:
                    skipped_ranks.append(f"{rank_name} (ç¼ºå°‘åˆ—: {', '.join(missing_cols)})")
                    continue
                df['è¯„è®ºæ–‡ä»¶è·¯å¾„'] = df['æ­Œæ›²ID'].apply(
                    lambda song_id: str(comment_dir / f"comments_{song_id}.csv") if (comment_dir / f"comments_{song_id}.csv").exists() else ""
                )
                df['æ¦œå•ç±»å‹'] = rank_name.strip()
                all_rank_data.append(df)
                found_ranks.append(rank_name)
            except Exception as e:
                skipped_ranks.append(f"{rank_name} (è¯»å–é”™è¯¯: {str(e)})")
        else:
            skipped_ranks.append(f"{rank_name} (æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨)")
    if not all_rank_data:
        return pd.DataFrame(), found_ranks, skipped_ranks
    combined_df = pd.concat(all_rank_data, ignore_index=True)
    numeric_cols = ['è¯„è®ºæ€»æ•°', 'ç§¯æè¯„è®ºæ•°', 'æ¶ˆæè¯„è®ºæ•°', 'ä¸­ç«‹è¯„è®ºæ•°', 'ç§¯æè¯„è®ºå æ¯”', 'æ¶ˆæè¯„è®ºå æ¯”', 'ä¸­ç«‹è¯„è®ºå æ¯”']
    for col in numeric_cols:
        combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce').fillna(0)
    combined_df['æƒ…æ„Ÿå€¾å‘'] = combined_df.apply(
        lambda x: 'ç§¯æ' if x['ç§¯æè¯„è®ºå æ¯”'] > x['æ¶ˆæè¯„è®ºå æ¯”'] and x['ç§¯æè¯„è®ºå æ¯”'] > 0.3 
                  else 'æ¶ˆæ' if x['æ¶ˆæè¯„è®ºå æ¯”'] > x['ç§¯æè¯„è®ºå æ¯”'] and x['æ¶ˆæè¯„è®ºå æ¯”'] > 0.3
                  else 'ä¸­ç«‹', axis=1
    )
    
    # ä¸ºæ¨èç³»ç»Ÿæ·»åŠ çš„é¢„å¤„ç†
    # 1. åˆ›å»ºæ­Œæ›²ç‰¹å¾æ–‡æœ¬ï¼ˆåç§°+æ­Œæ‰‹+æ¦œå•ç±»å‹+é«˜é¢‘å­—çœ¼+æƒ…æ„Ÿå€¾å‘ï¼‰
    combined_df['ç‰¹å¾æ–‡æœ¬'] = combined_df['æ­Œæ›²åç§°'] + ' ' + combined_df['æ­Œæ‰‹'] + ' ' + combined_df['æ¦œå•ç±»å‹'] + ' ' + combined_df['é«˜é¢‘å­—çœ¼'].fillna('') + ' ' + combined_df['æƒ…æ„Ÿå€¾å‘']
    # 2. å¤„ç†ç¼ºå¤±å€¼
    combined_df['ç‰¹å¾æ–‡æœ¬'] = combined_df['ç‰¹å¾æ–‡æœ¬'].fillna('')
    
    return combined_df, found_ranks, skipped_ranks

def load_all_data(selected_data_source):
    if selected_data_source == "13ç±»é£æ ¼æ­Œå•æ•°æ®":
        df, found, skipped, dup_count = load_style_playlist_data()
        load_summary = {
            "data_type": "é£æ ¼æ­Œå•",
            "found_count": len(found),
            "total_count": len(TYPE_LIST_STYLE),
            "found_items": found,
            "skipped_items": skipped,
            "dup_count": dup_count
        }
    else:
        df, found, skipped = load_rank_comment_data()
        load_summary = {
            "data_type": "æ¦œå•è¯„è®º",
            "found_count": len(found),
            "total_count": len(TYPE_LIST_RANK),
            "found_items": found,
            "skipped_items": skipped,
            "dup_count": 0
        }
    return df, load_summary

# ---------------------- æ•°æ®æ¦‚è§ˆå¡ç‰‡ï¼ˆä¿æŒä¸å˜ï¼‰ ----------------------
def display_data_overview(df, data_source):
    st.markdown('<div class="sub-title">ğŸ“ˆ æ•°æ®æ¦‚è§ˆ</div>', unsafe_allow_html=True)
    if data_source == "13ç±»é£æ ¼æ­Œå•æ•°æ®":
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #1DB954;">æ€»æ­Œå•æ•°é‡</h4>
                <p style="font-size: 24px; font-weight: bold;">{:,}</p>
            </div>
            """.format(len(df)), unsafe_allow_html=True)
        with col2:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #FF6B6B;">æ€»æ’­æ”¾æ¬¡æ•°</h4>
                <p style="font-size: 24px; font-weight: bold;">{:,}</p>
            </div>
            """.format(df['æ’­æ”¾æ¬¡æ•°'].sum()), unsafe_allow_html=True)
        with col3:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #4ECDC4;">æ€»æ”¶è—é‡</h4>
                <p style="font-size: 24px; font-weight: bold;">{:,}</p>
            </div>
            """.format(df['æ”¶è—é‡'].sum()), unsafe_allow_html=True)
        with col4:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #9B59B6;">å¹³å‡æ­Œå•é•¿åº¦</h4>
                <p style="font-size: 24px; font-weight: bold;">{:.1f}</p>
            </div>
            """.format(df['æ­Œå•é•¿åº¦'].mean()), unsafe_allow_html=True)
        col5, col6, col7 = st.columns(3)
        with col5:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #F39C12;">æ€»è¯„è®ºæ•°</h4>
                <p style="font-size: 24px; font-weight: bold;">{:,}</p>
            </div>
            """.format(df['è¯„è®ºæ•°'].sum()), unsafe_allow_html=True)
        with col6:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #8E44AD;">æ€»è½¬å‘é‡</h4>
                <p style="font-size: 24px; font-weight: bold;">{:,}</p>
            </div>
            """.format(df['è½¬å‘é‡'].sum()), unsafe_allow_html=True)
        with col7:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #16A085;">å¹³å‡æ”¶è—æ’­æ”¾æ¯”(%)</h4>
                <p style="font-size: 24px; font-weight: bold;">{:.2f}</p>
            </div>
            """.format(df['æ”¶è—æ’­æ”¾æ¯”'].mean()), unsafe_allow_html=True)
    else:
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #1DB954;">æ€»æ­Œæ›²æ•°é‡</h4>
                <p style="font-size: 24px; font-weight: bold;">{:,}</p>
            </div>
            """.format(len(df)), unsafe_allow_html=True)
        with col2:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #FF6B6B;">æ€»è¯„è®ºæ•°</h4>
                <p style="font-size: 24px; font-weight: bold;">{:,}</p>
            </div>
            """.format(df['è¯„è®ºæ€»æ•°'].sum()), unsafe_allow_html=True)
        with col3:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #4ECDC4;">å¹³å‡ç§¯æè¯„è®ºå æ¯”(%)</h4>
                <p style="font-size: 24px; font-weight: bold;">{:.2f}</p>
            </div>
            """.format(df['ç§¯æè¯„è®ºå æ¯”'].mean() * 100), unsafe_allow_html=True)
        with col4:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #9B59B6;">ç§¯ææƒ…æ„Ÿæ­Œæ›²æ•°</h4>
                <p style="font-size: 24px; font-weight: bold;">{:,}</p>
            </div>
            """.format(len(df[df['æƒ…æ„Ÿå€¾å‘'] == 'ç§¯æ'])), unsafe_allow_html=True)
        col5, col6, col7 = st.columns(3)
        with col5:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #F39C12;">æ¶ˆææƒ…æ„Ÿæ­Œæ›²æ•°</h4>
                <p style="font-size: 24px; font-weight: bold;">{:,}</p>
            </div>
            """.format(len(df[df['æƒ…æ„Ÿå€¾å‘'] == 'æ¶ˆæ'])), unsafe_allow_html=True)
        with col6:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #8E44AD;">ä¸­ç«‹æƒ…æ„Ÿæ­Œæ›²æ•°</h4>
                <p style="font-size: 24px; font-weight: bold;">{:,}</p>
            </div>
            """.format(len(df[df['æƒ…æ„Ÿå€¾å‘'] == 'ä¸­ç«‹'])), unsafe_allow_html=True)
        with col7:
            st.markdown("""
            <div class="metric-card">
                <h4 style="color: #16A085;">å¹³å‡å•é¦–æ­Œæ›²è¯„è®ºæ•°</h4>
                <p style="font-size: 24px; font-weight: bold;">{:.1f}</p>
            </div>
            """.format(df['è¯„è®ºæ€»æ•°'].mean()), unsafe_allow_html=True)

# ---------------------- é«˜çº§å¯è§†åŒ–æ¨¡å—ï¼ˆå®Œæ•´ä»£ç ï¼‰ ----------------------
def plot_style_playlist_visualizations(df):
    """13ç±»é£æ ¼æ­Œå•å¯è§†åŒ–"""
    if df.empty:
        st.warning("æ²¡æœ‰å¯ä¾›å¯è§†åŒ–çš„é£æ ¼æ­Œå•æ•°æ®")
        return
    
    st.markdown('<div class="sub-title">ğŸ¯ é£æ ¼æ­Œå•æ·±åº¦åˆ†æ</div>', unsafe_allow_html=True)
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5 = st.tabs(['åˆ†ç±»åˆ†æ', 'æ—¶é—´è¶‹åŠ¿', 'ç›¸å…³æ€§åˆ†æ', 'é«˜çº§æ´å¯Ÿ', 'æ™ºèƒ½æ¨è'])
    
    # Tab 1: åˆ†ç±»åˆ†æ
    with tab1:
        col1, col2 = st.columns(2)
        
        with col1:
            # å„åˆ†ç±»æ­Œå•æ•°é‡
            cat_counts = df['åˆ†ç±»'].value_counts()
            fig = px.bar(
                x=cat_counts.index,
                y=cat_counts.values,
                title='å„åˆ†ç±»æ­Œå•æ•°é‡åˆ†å¸ƒ',
                labels={'x': 'åˆ†ç±»', 'y': 'æ­Œå•æ•°é‡'},
                color=cat_counts.values,
                color_continuous_scale='Reds',
                template='plotly_white'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
    
        with col2:
            # å„åˆ†ç±»å¹³å‡æ’­æ”¾é‡
            avg_play = df.groupby('åˆ†ç±»')['æ’­æ”¾æ¬¡æ•°'].mean().sort_values(ascending=False)
            fig = px.bar(
                x=avg_play.index,
                y=avg_play.values,
                title='å„åˆ†ç±»å¹³å‡æ’­æ”¾é‡',
                labels={'x': 'åˆ†ç±»', 'y': 'å¹³å‡æ’­æ”¾æ¬¡æ•°'},
                color=avg_play.values,
                color_continuous_scale='Blues',
                template='plotly_white'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        # å„åˆ†ç±»ç»¼åˆæŒ‡æ ‡é›·è¾¾å›¾
        st.markdown("### å„åˆ†ç±»ç»¼åˆè¡¨ç°å¯¹æ¯”")
        # ä¿®æ”¹ç‚¹ï¼šè·å–æ‰€æœ‰åˆ†ç±»ï¼Œä¸å†é™åˆ¶å‰6ç±»
        all_categories = df['åˆ†ç±»'].unique()  
        cat_metrics = df[df['åˆ†ç±»'].isin(all_categories)].groupby('åˆ†ç±»').agg({
            'æ’­æ”¾æ¬¡æ•°': 'mean',
            'æ”¶è—é‡': 'mean',
            'è¯„è®ºæ•°': 'mean',
            'æ­Œå•é•¿åº¦': 'mean'
        }).reset_index()
    
        # æ•°æ®æ ‡å‡†åŒ–
        for col in ['æ’­æ”¾æ¬¡æ•°', 'æ”¶è—é‡', 'è¯„è®ºæ•°', 'æ­Œå•é•¿åº¦']:
            cat_metrics[col] = (cat_metrics[col] - cat_metrics[col].min()) / (cat_metrics[col].max() - cat_metrics[col].min())
    
        fig = go.Figure()
        for _, row in cat_metrics.iterrows():
            fig.add_trace(go.Scatterpolar(
                r=[row['æ’­æ”¾æ¬¡æ•°'], row['æ”¶è—é‡'], row['è¯„è®ºæ•°'], row['æ­Œå•é•¿åº¦']],
                theta=['æ’­æ”¾æ¬¡æ•°', 'æ”¶è—é‡', 'è¯„è®ºæ•°', 'æ­Œå•é•¿åº¦'],
                name=row['åˆ†ç±»']
            ))
        
        fig.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
            showlegend=True,
            height=500,
            template='plotly_white'
        )
        st.plotly_chart(fig, use_container_width=True)

    
    # Tab 2: æ—¶é—´è¶‹åŠ¿
    with tab2:
        # æŒ‰æœˆä»½ç»Ÿè®¡ç­›é€‰åæ­Œå•çš„åˆ›å»ºæ•°é‡ï¼ˆæ•´ä½“è¶‹åŠ¿ï¼‰
        monthly_trend = df.groupby('åˆ›å»ºæœˆä»½').size().reset_index(name='æ­Œå•æ•°é‡')
        monthly_trend['åˆ›å»ºæœˆä»½'] = monthly_trend['åˆ›å»ºæœˆä»½'].astype(str)
    
        fig = px.line(
            monthly_trend,
            x='åˆ›å»ºæœˆä»½',
            y='æ­Œå•æ•°é‡',
            title='ç­›é€‰åæ­Œå•åˆ›å»ºæ—¶é—´è¶‹åŠ¿',
            labels={'åˆ›å»ºæœˆä»½': 'æœˆä»½', 'æ­Œå•æ•°é‡': 'æ–°å¢æ­Œå•æ•°é‡'},
            template='plotly_white',
            markers=True
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        # è¿‘6ä¸ªæœˆå„åˆ†ç±»æ­Œå•å¢é•¿æƒ…å†µï¼ˆåŸºäºç­›é€‰åçš„æ•°æ®ï¼‰
        if not df.empty and not df['åˆ›å»ºæ—¥æœŸ'].isna().all():
            # 1. ä»ç­›é€‰åçš„æ•°æ®ä¸­è·å–æœ€æ–°æœˆä»½ï¼ˆPeriodç±»å‹ï¼‰
            latest_month_period = df['åˆ›å»ºæ—¥æœŸ'].dt.to_period('M').max()
            latest_month_dt = latest_month_period.to_timestamp()  # è½¬ä¸ºdatetimeç”¨äºè®¡ç®—
            
            # 2. è®¡ç®—ç­›é€‰åæ•°æ®çš„"è¿‘6ä¸ªæœˆ"èµ·å§‹æ—¶é—´
            from dateutil.relativedelta import relativedelta
            six_months_ago_dt = latest_month_dt - relativedelta(months=6)
            six_months_ago_period = six_months_ago_dt.to_period('M')  # è½¬å›Periodç”¨äºç­›é€‰
            
            # 3. ä»ç­›é€‰åçš„æ•°æ®ä¸­ï¼Œå†ç­›é€‰è¿‘6ä¸ªæœˆçš„è®°å½•
            recent_data = df[df['åˆ›å»ºæœˆä»½'].between(six_months_ago_period, latest_month_period)]
        
            if len(recent_data) > 0:
                monthly_cat = recent_data.groupby(['åˆ›å»ºæœˆä»½', 'åˆ†ç±»']).size().reset_index(name='æ­Œå•æ•°é‡')
                monthly_cat['åˆ›å»ºæœˆä»½'] = monthly_cat['åˆ›å»ºæœˆä»½'].astype(str)
                
                fig = px.area(
                    monthly_cat,
                    x='åˆ›å»ºæœˆä»½',
                    y='æ­Œå•æ•°é‡',
                    color='åˆ†ç±»',
                    title='ç­›é€‰åè¿‘6ä¸ªæœˆå„åˆ†ç±»æ­Œå•å¢é•¿è¶‹åŠ¿',  # æ ‡é¢˜æ˜ç¡®æ ‡æ³¨"ç­›é€‰å"
                    labels={'åˆ›å»ºæœˆä»½': 'æœˆä»½', 'æ­Œå•æ•°é‡': 'æ­Œå•æ•°é‡'},
                    template='plotly_white'
                )
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("ç­›é€‰åçš„æ•°æ®ä¸­ï¼Œè¿‘6ä¸ªæœˆå†…æ²¡æœ‰æ‰¾åˆ°æ­Œå•æ•°æ®")
        else:
            st.info("ç­›é€‰åçš„æ•°æ®ä¸­æ²¡æœ‰æœ‰æ•ˆæ—¥æœŸæ•°æ®ï¼Œæ— æ³•å±•ç¤ºè¿‘6ä¸ªæœˆè¶‹åŠ¿")
    
    # Tab 3: ç›¸å…³æ€§åˆ†æ
    with tab3:
        col1, col2 = st.columns(2)
        
        with col1:
            # æ’­æ”¾é‡vsæ”¶è—é‡æ•£ç‚¹å›¾
            fig = px.scatter(
                df,
                x='æ’­æ”¾æ¬¡æ•°',
                y='æ”¶è—é‡',
                color='åˆ†ç±»',
                size='æ­Œå•é•¿åº¦',
                hover_data=['åç§°', 'åˆ›å»ºæ—¥æœŸ'],
                title='æ’­æ”¾é‡ vs æ”¶è—é‡',
                labels={'æ’­æ”¾æ¬¡æ•°': 'æ’­æ”¾æ¬¡æ•°', 'æ”¶è—é‡': 'æ”¶è—é‡'},
                opacity=0.7,
                template='plotly_white'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # æ’­æ”¾é‡vsè¯„è®ºæ•°æ•£ç‚¹å›¾
            fig = px.scatter(
                df,
                x='æ’­æ”¾æ¬¡æ•°',
                y='è¯„è®ºæ•°',
                color='åˆ†ç±»',
                size='æ”¶è—é‡',
                hover_data=['åç§°', 'åˆ›å»ºæ—¥æœŸ'],
                title='æ’­æ”¾é‡ vs è¯„è®ºæ•°',
                labels={'æ’­æ”¾æ¬¡æ•°': 'æ’­æ”¾æ¬¡æ•°', 'è¯„è®ºæ•°': 'è¯„è®ºæ•°'},
                opacity=0.7,
                template='plotly_white'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        # æ•°å€¼ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾
        numeric_features = ['æ’­æ”¾æ¬¡æ•°', 'æ”¶è—é‡', 'è½¬å‘é‡', 'è¯„è®ºæ•°', 'æ­Œå•é•¿åº¦', 'æ”¶è—æ’­æ”¾æ¯”', 'è¯„è®ºæ’­æ”¾æ¯”']
        corr_matrix = df[numeric_features].corr()
        
        fig = px.imshow(
            corr_matrix,
            title='ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾',
            labels=dict(color='ç›¸å…³ç³»æ•°'),
            x=numeric_features,
            y=numeric_features,
            color_continuous_scale='RdBu_r',
            template='plotly_white'
        )
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
    
    # Tab 4: é«˜çº§æ´å¯Ÿ
    with tab4:
        # Top 10 é«˜æ”¶è—æ’­æ”¾æ¯”æ­Œå•
        st.markdown("### Top 10 é«˜æ”¶è—ç‡æ­Œå•")
        # è¿‡æ»¤æ‰æ’­æ”¾æ¬¡æ•°ä¸º0çš„æ­Œå•ï¼Œé¿å…é™¤ä»¥é›¶é”™è¯¯
        high_fav_ratio_df = (
            df[df['æ’­æ”¾æ¬¡æ•°'] > 1000]
            .sort_values('æ”¶è—æ’­æ”¾æ¯”', ascending=False)
            .drop_duplicates(subset='åç§°', keep='first')
            .nlargest(10, 'æ”¶è—æ’­æ”¾æ¯”')
            [['åç§°', 'åˆ†ç±»', 'æ’­æ”¾æ¬¡æ•°', 'æ”¶è—é‡', 'æ”¶è—æ’­æ”¾æ¯”', 'åˆ›å»ºæ—¥æœŸ']]
        )
        
        fig = px.bar(
            high_fav_ratio_df,
            x='åç§°',
            y='æ”¶è—æ’­æ”¾æ¯”',
            color='åˆ†ç±»',
            title='æ”¶è—ç‡æœ€é«˜çš„10ä¸ªæ­Œå• (æ”¶è—é‡/æ’­æ”¾é‡%)',
            labels={'åç§°': 'æ­Œå•åç§°', 'æ”¶è—æ’­æ”¾æ¯”': 'æ”¶è—ç‡(%)'},
            template='plotly_white',
            hover_data=['æ’­æ”¾æ¬¡æ•°', 'æ”¶è—é‡', 'åˆ›å»ºæ—¥æœŸ'],
            category_orders={"åç§°": high_fav_ratio_df.sort_values('æ”¶è—æ’­æ”¾æ¯”', ascending=False)['åç§°'].tolist()}
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        # æ­Œå•é•¿åº¦åˆ†å¸ƒ
        st.markdown("### æ­Œå•é•¿åº¦åˆ†å¸ƒ")
        # è®¡ç®—åˆé€‚çš„ nbins å€¼ï¼Œè¿™é‡Œå‡è®¾æ­Œå•é•¿åº¦æœ€å¤§å¯èƒ½åˆ° 10000ï¼Œä½ å¯æ ¹æ®å®é™…æ•°æ®è°ƒæ•´
        max_playlist_length = df['æ­Œå•é•¿åº¦'].max() if not df.empty else 10000
        nbins = int(max_playlist_length / 10)  
        fig = px.histogram(
            df,
            x='æ­Œå•é•¿åº¦',
            nbins=nbins,
            title='æ­Œå•é•¿åº¦åˆ†å¸ƒ',
            labels={'æ­Œå•é•¿åº¦': 'æ­Œæ›²æ•°é‡', 'count': 'æ­Œå•æ•°é‡'},
            color_discrete_sequence=['#4ECDC4'],
            template='plotly_white'
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        # æ ‡ç­¾äº‘ï¼ˆä½¿ç”¨Plotlyçš„æ¡å½¢å›¾æ¨¡æ‹Ÿï¼‰
        st.markdown("### çƒ­é—¨æ ‡ç­¾åˆ†æ")
        if 'tag1' in df.columns:
            # è¿‡æ»¤æ‰ç©ºæ ‡ç­¾
            tag_counts = df['tag1'].replace('', pd.NA).dropna().value_counts().head(15)
            if not tag_counts.empty:
                fig = px.bar(
                    x=tag_counts.values,
                    y=tag_counts.index,
                    orientation='h',
                    title='çƒ­é—¨æ ‡ç­¾ Top 15',
                    labels={'x': 'å‡ºç°æ¬¡æ•°', 'y': 'æ ‡ç­¾'},
                    color=tag_counts.values,
                    color_continuous_scale='Oranges',
                    template='plotly_white'
                )
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ ‡ç­¾æ•°æ®ã€‚")
        else:
            st.warning("æ•°æ®ä¸­ç¼ºå°‘ 'tag1' åˆ—ï¼Œæ— æ³•è¿›è¡Œçƒ­é—¨æ ‡ç­¾åˆ†æã€‚")
    
    # Tab 5: æ™ºèƒ½æ¨èï¼ˆæ–°å¢ï¼‰
    with tab5:
        st.markdown("### ğŸ¯ æ­Œå•æ™ºèƒ½æ¨èç³»ç»Ÿ")
        
        # åˆ›å»ºæ¨èæ¨¡å‹
        @st.cache_resource
        def create_playlist_recommendation_model(df):
            """åˆ›å»ºæ­Œå•æ¨èæ¨¡å‹"""
            # å‡†å¤‡æ–‡æœ¬æ•°æ®
            texts = df['ç‰¹å¾æ–‡æœ¬'].tolist()
            
            # åˆ›å»ºTF-IDFå‘é‡izer
            vectorizer = TfidfVectorizer(
                tokenizer=jieba.cut,
                stop_words=['çš„', 'äº†', 'æ˜¯', 'æˆ‘', 'åœ¨', 'å’Œ', 'ä¹Ÿ', 'éƒ½', 'å¾ˆ', 'å°±', 'è¿˜', 'æœ‰'],
                max_features=5000
            )
            
            # è½¬æ¢æ–‡æœ¬ä¸ºTF-IDFçŸ©é˜µ
            tfidf_matrix = vectorizer.fit_transform(texts)
            
            return vectorizer, tfidf_matrix
        
        # è·å–æ¨èæ¨¡å‹
        if not df.empty and 'ç‰¹å¾æ–‡æœ¬' in df.columns:
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ¨èæ¨¡å‹..."):
                vectorizer, tfidf_matrix = create_playlist_recommendation_model(df)
            
            # ç”¨æˆ·è¾“å…¥
            st.markdown("#### è¯·è¾“å…¥ä½ çš„éœ€æ±‚")
            user_query = st.text_input("ä¾‹å¦‚ï¼šæˆ‘æƒ³å¬ä¼¤æ„Ÿçš„åè¯­æ­Œæ›²ï¼Œé€‚åˆå¤œæ™šå¬çš„", "")
            
            # æ¨èå‚æ•°è®¾ç½®
            col1, col2 = st.columns(2)
            with col1:
                min_play_count = st.number_input("æœ€ä½æ’­æ”¾æ¬¡æ•°", min_value=0, value=10000)
            with col2:
                recommendation_count = st.number_input("æ¨èæ•°é‡", min_value=1, max_value=20, value=5)
            
            # æ‰§è¡Œæ¨è
            if st.button("è·å–æ¨è"):
                if not user_query:
                    st.warning("è¯·è¾“å…¥ä½ çš„éŸ³ä¹éœ€æ±‚")
                else:
                    with st.spinner("æ­£åœ¨ä¸ºä½ æ¨èæ­Œå•..."):
                        # å¤„ç†ç”¨æˆ·æŸ¥è¯¢
                        query_vector = vectorizer.transform([user_query])
                        
                        # è®¡ç®—ç›¸ä¼¼åº¦
                        similarities = cosine_similarity(query_vector, tfidf_matrix)[0]
                        
                        # åˆ›å»ºç›¸ä¼¼åº¦DataFrame
                        similarity_df = pd.DataFrame({
                            'index': range(len(similarities)),
                            'similarity': similarities
                        })
                        
                        # ç­›é€‰ç›¸ä¼¼åº¦é«˜çš„æ­Œå•
                        similarity_df = similarity_df[similarity_df['similarity'] > 0.1].sort_values('similarity', ascending=False)
                        
                        # è·å–æ¨èç»“æœ
                        recommendations = []
                        for _, row in similarity_df.iterrows():
                            if len(recommendations) >= recommendation_count:
                                break
                                
                            playlist_idx = int(row['index'])
                            playlist = df.iloc[playlist_idx]
                            
                            # è¿‡æ»¤æ¡ä»¶
                            if playlist['æ’­æ”¾æ¬¡æ•°'] >= min_play_count:
                                recommendations.append({
                                    'index': playlist_idx,
                                    'similarity': row['similarity'],
                                    'playlist': playlist
                                })
                        
                        # æ˜¾ç¤ºæ¨èç»“æœ
                        if recommendations:
                            st.markdown(f"#### ä¸ºä½ æ‰¾åˆ° {len(recommendations)} ä¸ªç¬¦åˆæ¡ä»¶çš„æ­Œå•ï¼š")
                            
                            for rec in recommendations:
                                playlist = rec['playlist']
                                similarity_score = rec['similarity']
                                
                                # ç”ŸæˆåŒ¹é…ç†ç”±
                                match_reasons = []
                                query_words = set(jieba.cut(user_query))
                                playlist_words = set(jieba.cut(playlist['ç‰¹å¾æ–‡æœ¬']))
                                common_words = query_words.intersection(playlist_words)
                                
                                if common_words:
                                    match_reasons.append(f"åŒ…å«å…³é”®è¯ï¼š{', '.join(common_words)}")
                                if playlist['æ”¶è—æ’­æ”¾æ¯”'] > df['æ”¶è—æ’­æ”¾æ¯”'].mean():
                                    match_reasons.append("æ”¶è—ç‡é«˜äºå¹³å‡æ°´å¹³")
                                if playlist['è¯„è®ºæ’­æ”¾æ¯”'] > df['è¯„è®ºæ’­æ”¾æ¯”'].mean():
                                    match_reasons.append("äº’åŠ¨ç‡è¾ƒé«˜")
                                
                                # æ˜¾ç¤ºæ¨èå¡ç‰‡
                                st.markdown(f"""
                                <div class="recommendation-card">
                                    <h4>{playlist['åç§°']}</h4>
                                    <p><strong>åˆ†ç±»ï¼š</strong>{playlist['åˆ†ç±»']}</p>
                                    <p><strong>æ’­æ”¾æ¬¡æ•°ï¼š</strong>{playlist['æ’­æ”¾æ¬¡æ•°']:,}</p>
                                    <p><strong>æ”¶è—é‡ï¼š</strong>{playlist['æ”¶è—é‡']:,}</p>
                                    <p><strong>æ­Œå•é•¿åº¦ï¼š</strong>{playlist['æ­Œå•é•¿åº¦']}é¦–æ­Œæ›²</p>
                                    <p><strong>åŒ¹é…ç†ç”±ï¼š</strong>{' | '.join(match_reasons) if match_reasons else 'ç»¼åˆç‰¹å¾åŒ¹é…'}</p>
                                    <span class="match-score">åŒ¹é…åº¦ï¼š{similarity_score:.2%}</span>
                                </div>
                                """, unsafe_allow_html=True)
                        else:
                            st.info("æ²¡æœ‰æ‰¾åˆ°å®Œå…¨åŒ¹é…çš„æ­Œå•ï¼Œå»ºè®®å°è¯•è°ƒæ•´æœç´¢å…³é”®è¯æˆ–é™ä½æ’­æ”¾æ¬¡æ•°è¦æ±‚")
        else:
            st.warning("æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ›å»ºæ¨èæ¨¡å‹")

from wordcloud import WordCloud
import matplotlib.pyplot as plt
from pathlib import Path

def plot_rank_comment_visualizations(df):
    """4ç±»æ¦œå•æ­Œæ›²è¯„è®ºå¯è§†åŒ–"""
    if df.empty:
        st.warning("æ²¡æœ‰å¯ä¾›å¯è§†åŒ–çš„æ¦œå•è¯„è®ºæ•°æ®")
        return
    
    st.markdown('<div class="sub-title">ğŸ¯ æ¦œå•æ­Œæ›²è¯„è®ºæ·±åº¦åˆ†æ</div>', unsafe_allow_html=True)
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5 = st.tabs(['æƒ…æ„Ÿåˆ†æ', 'è¯„è®ºé‡åˆ†æ', 'é«˜é¢‘è¯åˆ†æ', 'é«˜çº§æ´å¯Ÿ', 'æ™ºèƒ½æ¨è'])
    
    # Tab 1: æƒ…æ„Ÿåˆ†æ
    with tab1:
        col1, col2 = st.columns(2)
        
        with col1:
            # å„æ¦œå•æƒ…æ„Ÿå€¾å‘åˆ†å¸ƒ
            sentiment_counts = df.groupby(['æ¦œå•ç±»å‹', 'æƒ…æ„Ÿå€¾å‘']).size().reset_index(name='æ­Œæ›²æ•°é‡')
            fig = px.bar(
                sentiment_counts,
                x='æ¦œå•ç±»å‹',
                y='æ­Œæ›²æ•°é‡',
                color='æƒ…æ„Ÿå€¾å‘',
                barmode='group',
                title='å„æ¦œå•æ­Œæ›²æƒ…æ„Ÿå€¾å‘åˆ†å¸ƒ',
                labels={'æ­Œæ›²æ•°é‡': 'æ­Œæ›²æ•°é‡', 'æ¦œå•ç±»å‹': 'æ¦œå•ç±»å‹'},
                color_discrete_map={'ç§¯æ': '#2ECC40', 'æ¶ˆæ': '#FF4136', 'ä¸­ç«‹': '#AAAAAA'},
                template='plotly_white'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # å„æ¦œå•å¹³å‡æƒ…æ„Ÿå æ¯”
            avg_sentiment = df.groupby('æ¦œå•ç±»å‹').agg({
                'ç§¯æè¯„è®ºå æ¯”': 'mean',
                'æ¶ˆæè¯„è®ºå æ¯”': 'mean',
                'ä¸­ç«‹è¯„è®ºå æ¯”': 'mean'
            }).reset_index()
            
            fig = px.line(
                avg_sentiment,
                x='æ¦œå•ç±»å‹',
                y=['ç§¯æè¯„è®ºå æ¯”', 'æ¶ˆæè¯„è®ºå æ¯”', 'ä¸­ç«‹è¯„è®ºå æ¯”'],
                title='å„æ¦œå•å¹³å‡æƒ…æ„Ÿå æ¯”è¶‹åŠ¿',
                labels={'value': 'å¹³å‡å æ¯”', 'variable': 'æƒ…æ„Ÿç±»å‹'},
                template='plotly_white',
                markers=True
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        # æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒç®±çº¿å›¾
        st.markdown("### å„æ¦œå•æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ")
        fig = px.box(
            df,
            x='æ¦œå•ç±»å‹',
            y=['ç§¯æè¯„è®ºå æ¯”', 'æ¶ˆæè¯„è®ºå æ¯”'],
            title='å„æ¦œå•æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒç®±çº¿å›¾',
            labels={'value': 'æƒ…æ„Ÿå æ¯”', 'variable': 'æƒ…æ„Ÿç±»å‹'},
            color_discrete_map={'ç§¯æè¯„è®ºå æ¯”': '#2ECC40', 'æ¶ˆæè¯„è®ºå æ¯”': '#FF4136'},
            template='plotly_white'
        )
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
    
    # Tab 2: è¯„è®ºé‡åˆ†æ
    with tab2:
        col1, col2 = st.columns(2)
        
        with col1:
            # å„æ¦œå•è¯„è®ºæ€»æ•°åˆ†å¸ƒ
            fig = px.histogram(
                df,
                x='è¯„è®ºæ€»æ•°',
                color='æ¦œå•ç±»å‹',
                title='å„æ¦œå•æ­Œæ›²è¯„è®ºæ€»æ•°åˆ†å¸ƒ',
                labels={'è¯„è®ºæ€»æ•°': 'è¯„è®ºæ€»æ•°', 'count': 'æ­Œæ›²æ•°é‡'},
                template='plotly_white',
                opacity=0.7
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # å„æ¦œå•å¹³å‡è¯„è®ºæ•°
            avg_comments = df.groupby('æ¦œå•ç±»å‹')['è¯„è®ºæ€»æ•°'].agg(['mean', 'median', 'max']).reset_index()
            fig = px.bar(
                avg_comments,
                x='æ¦œå•ç±»å‹',
                y=['mean', 'median', 'max'],
                title='å„æ¦œå•æ­Œæ›²è¯„è®ºæ•°ç»Ÿè®¡',
                labels={'value': 'è¯„è®ºæ•°', 'variable': 'ç»Ÿè®¡ç±»å‹'},
                barmode='group',
                template='plotly_white'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        # è¯„è®ºæ•°ä¸æƒ…æ„Ÿå€¾å‘å…³ç³»
        st.markdown("### è¯„è®ºæ•°ä¸æƒ…æ„Ÿå€¾å‘å…³ç³»")
        fig = px.scatter(
            df,
            x='è¯„è®ºæ€»æ•°',
            y='ç§¯æè¯„è®ºå æ¯”',
            color='æ¦œå•ç±»å‹',
            size='æ¶ˆæè¯„è®ºå æ¯”',
            hover_data=['æ­Œæ›²åç§°', 'æ­Œæ‰‹'],
            title='è¯„è®ºæ€»æ•° vs ç§¯æè¯„è®ºå æ¯”',
            labels={'è¯„è®ºæ€»æ•°': 'è¯„è®ºæ€»æ•°', 'ç§¯æè¯„è®ºå æ¯”': 'ç§¯æè¯„è®ºå æ¯”'},
            template='plotly_white',
            opacity=0.7
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    # Tab 3: é«˜é¢‘è¯åˆ†æ
    with tab3:
        # åˆå¹¶æ‰€æœ‰é«˜é¢‘è¯
        all_keywords = []
        for keywords in df['é«˜é¢‘å­—çœ¼'].dropna():
            if keywords and keywords != '':
                all_keywords.extend([kw.strip() for kw in keywords.split(',') if kw.strip()])
        
        if all_keywords:
            # æ–°å¢ï¼šå°†é«˜é¢‘è¯åˆ—è¡¨è½¬æ¢ä¸ºæ–‡æœ¬å­—ç¬¦ä¸²
            keywords_text = ' '.join(all_keywords)  # ç”¨ç©ºæ ¼è¿æ¥é«˜é¢‘è¯ï¼Œä¾›è¯äº‘ä½¿ç”¨
            # 1. å®šä¹‰é¡¹ç›®å†…å­—ä½“è·¯å¾„ï¼ˆfontsæ–‡ä»¶å¤¹ä¸‹çš„simsun.ttcï¼‰
            font_dir = Path(__file__).parent / "fonts"
            font_path = font_dir / "STZHONGS.TTF"  # ç¡®ä¿å­—ä½“æ–‡ä»¶åæ­£ç¡®
            
            # 2. éªŒè¯å­—ä½“æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™å°è¯•ç³»ç»Ÿå­—ä½“ï¼Œæœ€åfallback
            if not font_path.exists():
                st.warning("é¡¹ç›®å†…å­—ä½“æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå°è¯•åŠ è½½ç³»ç»Ÿå­—ä½“...")
                # å°è¯•ç³»ç»Ÿå­—ä½“ï¼ˆå…¼å®¹ä¸åŒç¯å¢ƒï¼‰
                system_fonts = [
                    "C:/Windows/Fonts/STZHONGS.TTF"          # Windows
                ]
                for sys_font in system_fonts:
                    if Path(sys_font).exists():
                        font_path = Path(sys_font)
                        break
                else:
                    # æ‰€æœ‰å°è¯•å¤±è´¥ï¼Œç”¨é»˜è®¤å­—ä½“ï¼ˆå¯èƒ½æ— æ³•æ˜¾ç¤ºä¸­æ–‡ï¼Œä½†ä¸æŠ¥é”™ï¼‰
                    font_path = None
                    st.warning("ç³»ç»Ÿå­—ä½“ä¹Ÿæœªæ‰¾åˆ°ï¼Œè¯äº‘å¯èƒ½æ— æ³•æ˜¾ç¤ºä¸­æ–‡ï¼")

            # ç”Ÿæˆè¯äº‘
            wordcloud = WordCloud(
                font_path=str(font_path) if font_path else None,  # è·¯å¾„è½¬å­—ç¬¦ä¸²ï¼ˆWordCloudéœ€è¦strç±»å‹ï¼‰
                width=800,
                height=400,
                background_color='white',
                colormap='viridis',
                max_words=100,
                max_font_size=100,
                contour_width=3,
                contour_color=COLOR_PALETTE['primary']
            ).generate(keywords_text)  # ç°åœ¨ keywords_text å·²å®šä¹‰
                
            # æ˜¾ç¤ºè¯äº‘
            st.markdown("### é«˜é¢‘è¯äº‘å›¾")
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig)
            
            # åŸæ¥çš„é«˜é¢‘è¯æ¡å½¢å›¾å’Œæ¦œå•å¯¹æ¯”
            keyword_counts = Counter(all_keywords).most_common(20)
            keywords_df = pd.DataFrame(keyword_counts, columns=['å…³é”®è¯', 'å‡ºç°æ¬¡æ•°'])
            
            col1, col2 = st.columns(2)
            
            with col1:
                # é«˜é¢‘è¯è¯äº‘ï¼ˆæ¡å½¢å›¾æ¨¡æ‹Ÿï¼‰
                fig = px.bar(
                    keywords_df,
                    x='å‡ºç°æ¬¡æ•°',
                    y='å…³é”®è¯',
                    orientation='h',
                    title='æ‰€æœ‰æ­Œæ›²é«˜é¢‘å…³é”®è¯ Top 20',
                    labels={'å‡ºç°æ¬¡æ•°': 'å‡ºç°æ¬¡æ•°', 'å…³é”®è¯': 'å…³é”®è¯'},
                    color='å‡ºç°æ¬¡æ•°',
                    color_continuous_scale='Viridis',
                    template='plotly_white'
                )
                fig.update_layout(height=500)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # å„æ¦œå•é«˜é¢‘è¯å¯¹æ¯”ï¼ˆå–å‰5ä¸ªï¼‰
                st.markdown("### å„æ¦œå•Top5é«˜é¢‘è¯")
                rank_keywords = {}
                
                for rank in df['æ¦œå•ç±»å‹'].unique():
                    rank_df = df[df['æ¦œå•ç±»å‹'] == rank]
                    rank_keywords_list = []
                    
                    for keywords in rank_df['é«˜é¢‘å­—çœ¼'].dropna():
                        if keywords and keywords != '':
                            rank_keywords_list.extend([kw.strip() for kw in keywords.split(',') if kw.strip()])
                    
                    if rank_keywords_list:
                        rank_keywords[rank] = Counter(rank_keywords_list).most_common(5)
                
                # åˆ›å»ºè¡¨æ ¼æ˜¾ç¤º
                for rank, keywords in rank_keywords.items():
                    st.subheader(f"{rank}")
                    kw_df = pd.DataFrame(keywords, columns=['å…³é”®è¯', 'å‡ºç°æ¬¡æ•°'])
                    st.dataframe(kw_df, use_container_width=True)
        else:
            st.info("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„é«˜é¢‘è¯æ•°æ®")
  
    # Tab 4: é«˜çº§æ´å¯Ÿ
    with tab4:
        # Top 10 ç§¯æè¯„è®ºå æ¯”æœ€é«˜çš„æ­Œæ›²
        st.markdown("### Top 10 ç§¯æè¯„è®ºå æ¯”æœ€é«˜çš„æ­Œæ›²")
        top_positive = df.nlargest(10, 'ç§¯æè¯„è®ºå æ¯”')[['æ­Œæ›²åç§°', 'æ­Œæ‰‹', 'æ¦œå•ç±»å‹', 'ç§¯æè¯„è®ºå æ¯”', 'è¯„è®ºæ€»æ•°', 'é«˜é¢‘å­—çœ¼']]
        
        fig = px.bar(
            top_positive,
            x='æ­Œæ›²åç§°',
            y='ç§¯æè¯„è®ºå æ¯”',
            color='æ¦œå•ç±»å‹',
            title='ç§¯æè¯„è®ºå æ¯”æœ€é«˜çš„10é¦–æ­Œæ›²',
            labels={'æ­Œæ›²åç§°': 'æ­Œæ›²åç§°', 'ç§¯æè¯„è®ºå æ¯”': 'ç§¯æè¯„è®ºå æ¯”'},
            template='plotly_white',
            hover_data=['æ­Œæ‰‹', 'è¯„è®ºæ€»æ•°', 'é«˜é¢‘å­—çœ¼']
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
            
        # Top 10 æ¶ˆæè¯„è®ºå æ¯”æœ€é«˜çš„æ­Œæ›²
        st.markdown("### Top 10 æ¶ˆæè¯„è®ºå æ¯”æœ€é«˜çš„æ­Œæ›²")
        top_negative = df.nlargest(10, 'æ¶ˆæè¯„è®ºå æ¯”')[['æ­Œæ›²åç§°', 'æ­Œæ‰‹', 'æ¦œå•ç±»å‹', 'æ¶ˆæè¯„è®ºå æ¯”', 'è¯„è®ºæ€»æ•°', 'é«˜é¢‘å­—çœ¼']]
            
        fig = px.bar(
            top_negative,
            x='æ­Œæ›²åç§°',
            y='æ¶ˆæè¯„è®ºå æ¯”',
            color='æ¦œå•ç±»å‹',
            title='æ¶ˆæè¯„è®ºå æ¯”æœ€é«˜çš„10é¦–æ­Œæ›²',
            labels={'æ­Œæ›²åç§°': 'æ­Œæ›²åç§°', 'æ¶ˆæè¯„è®ºå æ¯”': 'æ¶ˆæè¯„è®ºå æ¯”'},
            template='plotly_white',
            hover_data=['æ­Œæ‰‹', 'è¯„è®ºæ€»æ•°', 'é«˜é¢‘å­—çœ¼'],
            color_discrete_map={'çƒ­æ­Œæ¦œ': '#FF4136', 'æ–°æ­Œæ¦œ': '#FF851B', 'é£™å‡æ¦œ': '#FFDC00', 'åŸåˆ›æ¦œ': '#B10DC9'}
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
            
        # å„æ¦œå•æ­Œæ›²æƒ…æ„Ÿç‰¹å¾é›·è¾¾å›¾
        st.markdown("### å„æ¦œå•æƒ…æ„Ÿç‰¹å¾å¯¹æ¯”")
        rank_sentiment = df.groupby('æ¦œå•ç±»å‹').agg({
            'ç§¯æè¯„è®ºå æ¯”': 'mean',
            'æ¶ˆæè¯„è®ºå æ¯”': 'mean',
            'ä¸­ç«‹è¯„è®ºå æ¯”': 'mean',
            'è¯„è®ºæ€»æ•°': 'mean'
        }).reset_index()
            
        # æ•°æ®æ ‡å‡†åŒ–
        for col in ['ç§¯æè¯„è®ºå æ¯”', 'æ¶ˆæè¯„è®ºå æ¯”', 'ä¸­ç«‹è¯„è®ºå æ¯”', 'è¯„è®ºæ€»æ•°']:
            rank_sentiment[col] = (rank_sentiment[col] - rank_sentiment[col].min()) / (rank_sentiment[col].max() - rank_sentiment[col].min())
            
        fig = go.Figure()
        for _, row in rank_sentiment.iterrows():
            fig.add_trace(go.Scatterpolar(
                r=[row['ç§¯æè¯„è®ºå æ¯”'], row['æ¶ˆæè¯„è®ºå æ¯”'], row['ä¸­ç«‹è¯„è®ºå æ¯”'], row['è¯„è®ºæ€»æ•°']],
                theta=['ç§¯æè¯„è®ºå æ¯”', 'æ¶ˆæè¯„è®ºå æ¯”', 'ä¸­ç«‹è¯„è®ºå æ¯”', 'å¹³å‡è¯„è®ºæ•°'],
                name=row['æ¦œå•ç±»å‹']
            ))
            
        fig.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
            showlegend=True,
            height=500,
            template='plotly_white'
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Tab 5: æ™ºèƒ½æ¨èï¼ˆæ–°å¢ï¼‰
    with tab5:
        st.markdown("### ğŸ¯ æ­Œæ›²æ™ºèƒ½æ¨èç³»ç»Ÿ")
        
        # åˆ›å»ºæ¨èæ¨¡å‹
        @st.cache_resource
        def create_song_recommendation_model(df):
            """åˆ›å»ºæ­Œæ›²æ¨èæ¨¡å‹"""
            # å‡†å¤‡æ–‡æœ¬æ•°æ®
            texts = df['ç‰¹å¾æ–‡æœ¬'].tolist()
            
            # åˆ›å»ºTF-IDFå‘é‡izer
            vectorizer = TfidfVectorizer(
                tokenizer=jieba.cut,
                stop_words=['çš„', 'äº†', 'æ˜¯', 'æˆ‘', 'åœ¨', 'å’Œ', 'ä¹Ÿ', 'éƒ½', 'å¾ˆ', 'å°±', 'è¿˜', 'æœ‰'],
                max_features=5000
            )
            
            # è½¬æ¢æ–‡æœ¬ä¸ºTF-IDFçŸ©é˜µ
            tfidf_matrix = vectorizer.fit_transform(texts)
            
            return vectorizer, tfidf_matrix
        
        # è·å–æ¨èæ¨¡å‹
        if not df.empty and 'ç‰¹å¾æ–‡æœ¬' in df.columns:
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ¨èæ¨¡å‹..."):
                vectorizer, tfidf_matrix = create_song_recommendation_model(df)
            
            # ç”¨æˆ·è¾“å…¥
            st.markdown("#### è¯·è¾“å…¥ä½ çš„éœ€æ±‚")
            user_query = st.text_input("ä¾‹å¦‚ï¼šæˆ‘æƒ³å¬ç§¯æå‘ä¸Šçš„æµè¡Œæ­Œæ›²ï¼Œæ­Œè¯è¦æœ‰æ¢¦æƒ³å’Œå¸Œæœ›", "")
            
            # æ¨èå‚æ•°è®¾ç½®
            col1, col2, col3 = st.columns(3)
            with col1:
                sentiment_preference = st.selectbox("æƒ…æ„Ÿå€¾å‘", ["ä¸é™", "ç§¯æ", "æ¶ˆæ", "ä¸­ç«‹"])
            with col2:
                min_comment_count = st.number_input("æœ€ä½è¯„è®ºæ•°", min_value=0, value=100)
            with col3:
                recommendation_count = st.number_input("æ¨èæ•°é‡", min_value=1, max_value=20, value=5)
            
            # æ‰§è¡Œæ¨è
            if st.button("è·å–æ¨è"):
                if not user_query:
                    st.warning("è¯·è¾“å…¥ä½ çš„éŸ³ä¹éœ€æ±‚")
                else:
                    with st.spinner("æ­£åœ¨ä¸ºä½ æ¨èæ­Œæ›²..."):
                        # å¤„ç†ç”¨æˆ·æŸ¥è¯¢
                        query_vector = vectorizer.transform([user_query])
                        
                        # è®¡ç®—ç›¸ä¼¼åº¦
                        similarities = cosine_similarity(query_vector, tfidf_matrix)[0]
                        
                        # åˆ›å»ºç›¸ä¼¼åº¦DataFrame
                        similarity_df = pd.DataFrame({
                            'index': range(len(similarities)),
                            'similarity': similarities
                        })
                        
                        # ç­›é€‰ç›¸ä¼¼åº¦é«˜çš„æ­Œæ›²
                        similarity_df = similarity_df[similarity_df['similarity'] > 0.05].sort_values('similarity', ascending=False)
                        
                        # è·å–æ¨èç»“æœ
                        recommendations = []
                        for _, row in similarity_df.iterrows():
                            if len(recommendations) >= recommendation_count:
                                break
                                
                            song_idx = int(row['index'])
                            song = df.iloc[song_idx]
                            
                            # è¿‡æ»¤æ¡ä»¶
                            if song['è¯„è®ºæ€»æ•°'] >= min_comment_count:
                                if sentiment_preference == "ä¸é™" or song['æƒ…æ„Ÿå€¾å‘'] == sentiment_preference:
                                    recommendations.append({
                                        'index': song_idx,
                                        'similarity': row['similarity'],
                                        'song': song
                                    })
                        
                        # æ˜¾ç¤ºæ¨èç»“æœ
                        if recommendations:
                            st.markdown(f"#### ä¸ºä½ æ‰¾åˆ° {len(recommendations)} é¦–ç¬¦åˆæ¡ä»¶çš„æ­Œæ›²ï¼š")
                            
                            for rec in recommendations:
                                song = rec['song']
                                similarity_score = rec['similarity']
                                
                                # ç”ŸæˆåŒ¹é…ç†ç”±
                                match_reasons = []
                                query_words = set(jieba.cut(user_query))
                                song_words = set(jieba.cut(song['ç‰¹å¾æ–‡æœ¬']))
                                common_words = query_words.intersection(song_words)
                                
                                if common_words:
                                    match_reasons.append(f"åŒ…å«å…³é”®è¯ï¼š{', '.join(common_words)}")
                                if song['æƒ…æ„Ÿå€¾å‘'] == 'ç§¯æ' and song['ç§¯æè¯„è®ºå æ¯”'] > df['ç§¯æè¯„è®ºå æ¯”'].mean():
                                    match_reasons.append("ç§¯æè¯„è®ºå æ¯”è¾ƒé«˜")
                                if song['è¯„è®ºæ€»æ•°'] > df['è¯„è®ºæ€»æ•°'].mean():
                                    match_reasons.append("äººæ°”è¾ƒé«˜")
                                
                                # æ˜¾ç¤ºæ¨èå¡ç‰‡
                                st.markdown(f"""
                                <div class="recommendation-card">
                                    <h4>{song['æ­Œæ›²åç§°']} - {song['æ­Œæ‰‹']}</h4>
                                    <p><strong>æ¦œå•ï¼š</strong>{song['æ¦œå•ç±»å‹']}</p>
                                    <p><strong>è¯„è®ºæ•°ï¼š</strong>{song['è¯„è®ºæ€»æ•°']:,}</p>
                                    <p><strong>æƒ…æ„Ÿå€¾å‘ï¼š</strong>{song['æƒ…æ„Ÿå€¾å‘']} (ç§¯æ: {song['ç§¯æè¯„è®ºå æ¯”']:.1%}, æ¶ˆæ: {song['æ¶ˆæè¯„è®ºå æ¯”']:.1%})</p>
                                    <p><strong>é«˜é¢‘å…³é”®è¯ï¼š</strong>{song['é«˜é¢‘å­—çœ¼'] if pd.notna(song['é«˜é¢‘å­—çœ¼']) else 'æ— '}</p>
                                    <p><strong>åŒ¹é…ç†ç”±ï¼š</strong>{' | '.join(match_reasons) if match_reasons else 'ç»¼åˆç‰¹å¾åŒ¹é…'}</p>
                                    <span class="match-score">åŒ¹é…åº¦ï¼š{similarity_score:.2%}</span>
                                </div>
                                """, unsafe_allow_html=True)
                        else:
                            st.info("æ²¡æœ‰æ‰¾åˆ°å®Œå…¨åŒ¹é…çš„æ­Œæ›²ï¼Œå»ºè®®å°è¯•è°ƒæ•´æœç´¢å…³é”®è¯æˆ–é™ä½ç­›é€‰æ¡ä»¶")
        else:
            st.warning("æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ›å»ºæ¨èæ¨¡å‹")

# ---------------------- ä¸»ç•Œé¢å¸ƒå±€ä¸é€»è¾‘ ----------------------
def main():
    # é¡µé¢æ ‡é¢˜
    st.markdown('<div class="page-title">ğŸµ ç½‘æ˜“äº‘æ­Œå•+æ¦œå•è¯„è®ºç»¼åˆæ•°æ®åˆ†æå·¥å…·</div>', unsafe_allow_html=True)
    st.markdown("---")
    
    # æ•°æ®æºé€‰æ‹©
    selected_data_source = st.selectbox(
        "è¯·é€‰æ‹©è¦åˆ†æçš„æ•°æ®æº",
        ["13ç±»é£æ ¼æ­Œå•æ•°æ®", "4ç±»æ¦œå•æ­Œæ›²è¯„è®ºæ•°æ®"]
    )
    
    # åŠ è½½æ•°æ®ï¼ˆä½¿ç”¨st.spinneræ˜¾ç¤ºåŠ è½½çŠ¶æ€ï¼‰
    with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®ï¼Œè¯·ç¨å€™..."):
        df, load_summary = load_all_data(selected_data_source)
    
    # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
    if not df.empty:
        st.success(f"âœ… æˆåŠŸåŠ è½½ {load_summary['found_count']} / {load_summary['total_count']} ä¸ª{load_summary['data_type']}æ•°æ®")
        if load_summary['dup_count'] > 0:
            st.info(f"ğŸ” æ•°æ®å»é‡å®Œæˆï¼šå…±ç§»é™¤ {load_summary['dup_count']} æ¡é‡å¤æ•°æ®")
    else:
        st.warning("âš ï¸ æ•°æ®åŠ è½½å¤±è´¥æˆ–æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
    
    # æ˜¾ç¤ºè·³è¿‡çš„æ–‡ä»¶
    if load_summary['skipped_items']:
        with st.expander("âš ï¸ æŸ¥çœ‹è¢«è·³è¿‡çš„æ–‡ä»¶", expanded=False):
            for item in load_summary['skipped_items']:
                st.write(item)
    
    st.markdown("---")
    
    # æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
    if not df.empty:
        display_data_overview(df, selected_data_source)
    st.markdown("---")
    
    # --- æ ¸å¿ƒä¿®æ”¹ï¼šå°†ç­›é€‰æ¡ä»¶ä»ä¾§è¾¹æ ç§»è‡³ä¸»é¡µé¢ ---
    filtered_df = pd.DataFrame()
    if not df.empty:
        st.markdown('<div class="sub-title">ğŸ” ç­›é€‰æ¡ä»¶</div>', unsafe_allow_html=True)
        
        # ä½¿ç”¨expanderç»„ä»¶æ¥å®¹çº³æ‰€æœ‰ç­›é€‰å™¨ï¼Œä¿æŒé¡µé¢æ•´æ´
        with st.expander("å±•å¼€/æŠ˜å ç­›é€‰å™¨", expanded=True):
            if selected_data_source == "13ç±»é£æ ¼æ­Œå•æ•°æ®":
                # åˆ›å»ºä¸€ä¸ª2åˆ—çš„å¸ƒå±€æ¥æ”¾ç½®ç­›é€‰å™¨
                col1, col2 = st.columns(2)
                
                with col1:
                    # æ­Œå•åˆ†ç±»ç­›é€‰
                    selected_cats = st.multiselect(
                        "æ­Œå•åˆ†ç±»", 
                        options=df['åˆ†ç±»'].unique(), 
                        default=df['åˆ†ç±»'].unique()
                    )
                    
                    # æ’­æ”¾æ¬¡æ•°ç­›é€‰
                    play_min, play_max = st.slider(
                        "æ’­æ”¾æ¬¡æ•°èŒƒå›´",
                        min_value=int(df['æ’­æ”¾æ¬¡æ•°'].min()),
                        max_value=int(df['æ’­æ”¾æ¬¡æ•°'].max()),
                        value=(int(df['æ’­æ”¾æ¬¡æ•°'].min()), int(df['æ’­æ”¾æ¬¡æ•°'].max()))
                    )
                    
                    # æ”¶è—é‡ç­›é€‰
                    fav_min = st.number_input(
                        "æœ€å°æ”¶è—é‡", 
                        min_value=0, 
                        max_value=int(df['æ”¶è—é‡'].max()), 
                        value=0
                    )
                
                with col2:
                    # æ—¥æœŸç­›é€‰
                    has_dates = not df['åˆ›å»ºæ—¥æœŸ'].isna().all()
                    date_min_ts, date_max_ts = None, None
                    if has_dates:
                        date_min, date_max = st.date_input(
                            "åˆ›å»ºæ—¥æœŸèŒƒå›´",
                            value=(df['åˆ›å»ºæ—¥æœŸ'].min(), df['åˆ›å»ºæ—¥æœŸ'].max()),
                            min_value=df['åˆ›å»ºæ—¥æœŸ'].min(),
                            max_value=df['åˆ›å»ºæ—¥æœŸ'].max()
                        )
                        date_min_ts = pd.to_datetime(date_min)
                        date_max_ts = pd.to_datetime(date_max)
                    
                    # æ­Œå•é•¿åº¦ç­›é€‰
                    len_min, len_max = st.slider(
                        "æ­Œå•æ­Œæ›²æ•°é‡",
                        min_value=1,
                        max_value=int(df['æ­Œå•é•¿åº¦'].max()),
                        value=(1, int(df['æ­Œå•é•¿åº¦'].max()))
                    )
                
                # åº”ç”¨ç­›é€‰
                filtered_df = df[
                    (df['åˆ†ç±»'].isin(selected_cats)) &
                    (df['æ’­æ”¾æ¬¡æ•°'] >= play_min) &
                    (df['æ’­æ”¾æ¬¡æ•°'] <= play_max) &
                    (df['æ”¶è—é‡'] >= fav_min) &
                    (df['æ­Œå•é•¿åº¦'] >= len_min) &
                    (df['æ­Œå•é•¿åº¦'] <= len_max)
                ].copy()
                
                if has_dates and date_min_ts and date_max_ts:
                    filtered_df = filtered_df[
                        (filtered_df['åˆ›å»ºæ—¥æœŸ'] >= date_min_ts) &
                        (filtered_df['åˆ›å»ºæ—¥æœŸ'] <= date_max_ts)
                    ]
            
            else: # 4ç±»æ¦œå•æ­Œæ›²è¯„è®ºæ•°æ®
                # åˆ›å»ºä¸€ä¸ª2åˆ—çš„å¸ƒå±€æ¥æ”¾ç½®ç­›é€‰å™¨
                col1, col2 = st.columns(2)
                
                with col1:
                    # æ¦œå•ç±»å‹ç­›é€‰
                    selected_ranks = st.multiselect(
                        "æ¦œå•ç±»å‹",
                        options=df['æ¦œå•ç±»å‹'].unique(),
                        default=df['æ¦œå•ç±»å‹'].unique()
                    )
                    
                    # è¯„è®ºæ•°ç­›é€‰
                    comment_min, comment_max = st.slider(
                        "è¯„è®ºæ€»æ•°èŒƒå›´",
                        min_value=int(df['è¯„è®ºæ€»æ•°'].min()),
                        max_value=int(df['è¯„è®ºæ€»æ•°'].max()),
                        value=(int(df['è¯„è®ºæ€»æ•°'].min()), int(df['è¯„è®ºæ€»æ•°'].max()))
                    )
                
                with col2:
                    # æƒ…æ„Ÿå€¾å‘ç­›é€‰
                    selected_sentiments = st.multiselect(
                        "æƒ…æ„Ÿå€¾å‘",
                        options=['ç§¯æ', 'æ¶ˆæ', 'ä¸­ç«‹'],
                        default=['ç§¯æ', 'æ¶ˆæ', 'ä¸­ç«‹']
                    )
                    
                    # ç§¯æè¯„è®ºå æ¯”ç­›é€‰
                    pos_ratio_min, pos_ratio_max = st.slider(
                        "ç§¯æè¯„è®ºå æ¯”èŒƒå›´",
                        min_value=0.0,
                        max_value=1.0,
                        value=(0.0, 1.0),
                        step=0.01
                    )
                
                # åº”ç”¨ç­›é€‰
                filtered_df = df[
                    (df['æ¦œå•ç±»å‹'].isin(selected_ranks)) &
                    (df['è¯„è®ºæ€»æ•°'] >= comment_min) &
                    (df['è¯„è®ºæ€»æ•°'] <= comment_max) &
                    (df['æƒ…æ„Ÿå€¾å‘'].isin(selected_sentiments)) &
                    (df['ç§¯æè¯„è®ºå æ¯”'] >= pos_ratio_min) &
                    (df['ç§¯æè¯„è®ºå æ¯”'] <= pos_ratio_max)
                ].copy()

    # æ˜¾ç¤ºç­›é€‰ç»“æœ
    if not df.empty:
        st.markdown('<div class="sub-title">ğŸ“‹ ç­›é€‰ç»“æœ</div>', unsafe_allow_html=True)
        st.markdown(f"**ç¬¦åˆæ¡ä»¶çš„è®°å½•æ•°é‡ï¼š{len(filtered_df)}**")
        
        # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
        with st.expander("æŸ¥çœ‹è¯¦ç»†æ•°æ®", expanded=False):
            if selected_data_source == "13ç±»é£æ ¼æ­Œå•æ•°æ®":
                display_cols = ['åç§°', 'åˆ†ç±»', 'åˆ›å»ºæ—¥æœŸ', 'æ’­æ”¾æ¬¡æ•°', 'æ”¶è—é‡', 'è¯„è®ºæ•°', 'æ­Œå•é•¿åº¦', 'tag1']
            else:
                display_cols = ['æ­Œæ›²åç§°', 'æ­Œæ‰‹', 'æ¦œå•ç±»å‹', 'è¯„è®ºæ€»æ•°', 'ç§¯æè¯„è®ºæ•°', 'æ¶ˆæè¯„è®ºæ•°', 'ä¸­ç«‹è¯„è®ºæ•°', 'æƒ…æ„Ÿå€¾å‘', 'é«˜é¢‘å­—çœ¼']
            
            # ç¡®ä¿æ‰€æœ‰è¦æ˜¾ç¤ºçš„åˆ—éƒ½å­˜åœ¨äºfiltered_dfä¸­
            display_cols = [col for col in display_cols if col in filtered_df.columns]
            st.dataframe(
                filtered_df[display_cols],
                height=400,
                use_container_width=True
            )
        
        # æ¦œå•è¯„è®ºæ•°æ®ä¸“å± - æŸ¥çœ‹å•é¦–æ­Œæ›²è¯¦ç»†è¯„è®º
        if selected_data_source == "4ç±»æ¦œå•æ­Œæ›²è¯„è®ºæ•°æ®" and not filtered_df.empty:
            st.markdown("---")
            st.markdown('<div class="sub-title">ğŸ’¬ æŸ¥çœ‹å•é¦–æ­Œæ›²è¯¦ç»†è¯„è®º</div>', unsafe_allow_html=True)
            
            # ä¸‹æ‹‰é€‰æ‹©è¦æŸ¥çœ‹çš„æ­Œæ›²
            song_options = filtered_df.apply(
                lambda x: f"{x['æ­Œæ›²åç§°']} - {x['æ­Œæ‰‹']}ï¼ˆ{x['æ¦œå•ç±»å‹']}ï¼‰", axis=1
            ).tolist()
            if song_options: # ç¡®ä¿åˆ—è¡¨ä¸ä¸ºç©º
                selected_song_idx = st.selectbox("é€‰æ‹©æ­Œæ›²", range(len(song_options)), format_func=lambda i: song_options[i])
                
                # è·å–é€‰ä¸­æ­Œæ›²çš„è¯„è®ºæ–‡ä»¶è·¯å¾„
                selected_song = filtered_df.iloc[selected_song_idx]
                comment_file_path = selected_song.get('è¯„è®ºæ–‡ä»¶è·¯å¾„', "") # ä½¿ç”¨.get()é¿å…KeyError
                
                if comment_file_path and comment_file_path != "":
                    # åŠ è½½è¯„è®ºæ•°æ®
                    try:
                        comments_df = pd.read_csv(comment_file_path, encoding='utf-8-sig')
                        
                        # è¯„è®ºç­›é€‰åŠŸèƒ½
                        st.markdown("#### è¯„è®ºç­›é€‰")
                        col1, col2 = st.columns(2)
                        with col1:
                            comment_search = st.text_input("æœç´¢è¯„è®ºå†…å®¹")
                        with col2:
                            sentiment_filter = st.selectbox("ç­›é€‰æƒ…æ„Ÿå€¾å‘", ["å…¨éƒ¨", "ç§¯æ", "æ¶ˆæ", "ä¸­ç«‹"])
                        
                        # åº”ç”¨ç­›é€‰
                        filtered_comments = comments_df.copy()
                        if comment_search:
                            filtered_comments = filtered_comments[filtered_comments['è¯„è®ºå†…å®¹'].str.contains(comment_search, na=False)]
                        
                        # æ ¹æ®æƒ…æ„Ÿå¾—åˆ†ç­›é€‰
                        if sentiment_filter != "å…¨éƒ¨" and 'æƒ…æ„Ÿå¾—åˆ†' in filtered_comments.columns:
                            if sentiment_filter == "ç§¯æ":
                                filtered_comments = filtered_comments[filtered_comments['æƒ…æ„Ÿå¾—åˆ†'] >= POSITIVE_THRESHOLD]
                            elif sentiment_filter == "æ¶ˆæ":
                                filtered_comments = filtered_comments[filtered_comments['æƒ…æ„Ÿå¾—åˆ†'] <= NEGATIVE_THRESHOLD]
                            else: # ä¸­ç«‹
                                filtered_comments = filtered_comments[
                                    (filtered_comments['æƒ…æ„Ÿå¾—åˆ†'] > NEGATIVE_THRESHOLD) & 
                                    (filtered_comments['æƒ…æ„Ÿå¾—åˆ†'] < POSITIVE_THRESHOLD)
                                ]
                        
                        # æ˜¾ç¤ºè¯„è®ºç»Ÿè®¡
                        st.markdown(f"**å…±æ‰¾åˆ° {len(filtered_comments)} æ¡è¯„è®ºï¼ˆå…± {len(comments_df)} æ¡ï¼‰**")
                        
                        # åˆ†é¡µæ˜¾ç¤ºè¯„è®ºï¼ˆæ¯é¡µ20æ¡ï¼‰
                        page_size = 20
                        total_pages = (len(filtered_comments) + page_size - 1) // page_size
                        page = st.number_input("é¡µç ", min_value=1, max_value=total_pages, value=1)
                        start_idx = (page - 1) * page_size
                        end_idx = start_idx + page_size
                        page_comments = filtered_comments.iloc[start_idx:end_idx]
                        
                        # æ˜¾ç¤ºè¯„è®ºè¡¨æ ¼
                        comment_display_cols = ['ç”¨æˆ·å', 'ç”¨æˆ·åŸå¸‚', 'è¯„è®ºå†…å®¹', 'ç‚¹èµæ•°', 'è¯„è®ºæ—¶é—´']
                        if 'æƒ…æ„Ÿå¾—åˆ†' in page_comments.columns:
                            comment_display_cols.append('æƒ…æ„Ÿå¾—åˆ†')
                        st.dataframe(
                            page_comments[comment_display_cols],
                            height=500,
                            use_container_width=True
                        )
                        
                        # å¯¼å‡ºå½“å‰æ­Œæ›²è¯„è®º
                        if st.button("å¯¼å‡ºå½“å‰æ­Œæ›²è¯„è®ºä¸ºCSV"):
                            export_path = DATA_DIR / f"{selected_song['æ­Œæ›²åç§°']}_{selected_song['æ­Œæ‰‹']}_è¯„è®º.csv"
                            # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
                            export_path = Path(str(export_path).replace('/', '').replace('\\', '').replace('*', '').replace('?', '').replace('"', '').replace('<', '').replace('>', '').replace('|', ''))
                            comments_df.to_csv(export_path, index=False, encoding='utf-8-sig')
                            st.success(f"âœ… è¯„è®ºå·²å¯¼å‡ºè‡³: {export_path}")
                    
                    except Exception as e:
                        st.error(f"åŠ è½½è¯„è®ºå¤±è´¥: {str(e)}")
                else:
                    st.warning("è¯¥æ­Œæ›²æ²¡æœ‰å¯¹åº”çš„è¯„è®ºæ–‡ä»¶æˆ–è¯„è®ºæ–‡ä»¶ä¸å­˜åœ¨")
        
        st.markdown("---")
        
        # é«˜çº§å¯è§†åŒ–
        if not filtered_df.empty:
            st.markdown("---")
            if selected_data_source == "13ç±»é£æ ¼æ­Œå•æ•°æ®":
                plot_style_playlist_visualizations(filtered_df)
            else:
                plot_rank_comment_visualizations(filtered_df)
        else:
            st.warning("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ã€‚")
        
        # å¯¼å‡ºåŠŸèƒ½
        st.markdown("---")
        st.markdown('<div class="sub-title">ğŸ’¾ ç»“æœå¯¼å‡º</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("å¯¼å‡ºç­›é€‰åæ•°æ®ä¸ºCSVæ–‡ä»¶"):
                if not filtered_df.empty:
                    export_path = DATA_DIR / f"ç­›é€‰åçš„{load_summary['data_type']}æ•°æ®.csv"
                    filtered_df.to_csv(export_path, index=False, encoding='utf-8-sig')
                    st.success(f"âœ… CSVæ–‡ä»¶å·²å¯¼å‡ºè‡³: {export_path}")
                else:
                    st.warning("âŒ æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®ã€‚")
        
        with col2:
            if st.button("å¯¼å‡ºç­›é€‰åæ•°æ®ä¸ºExcelæ–‡ä»¶"):
                if not filtered_df.empty:
                    export_path = DATA_DIR / f"ç­›é€‰åçš„{load_summary['data_type']}æ•°æ®.xlsx"
                    filtered_df.to_excel(export_path, index=False, engine='openpyxl')
                    st.success(f"âœ… Excelæ–‡ä»¶å·²å¯¼å‡ºè‡³: {export_path}")
                else:
                    st.warning("âŒ æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®ã€‚")
    else:
        st.error("æ— æ³•æ˜¾ç¤ºæ•°æ®åˆ†æå’Œç­›é€‰åŠŸèƒ½ï¼Œå› ä¸ºæ•°æ®åŠ è½½å¤±è´¥ã€‚")

# ---------------------- è¿è¡Œå…¥å£ ----------------------
if __name__ == "__main__":
    main()
